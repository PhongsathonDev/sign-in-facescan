import cv2
import numpy as np
import pickle
import time
from insightface.app import FaceAnalysis
from PIL import ImageFont, ImageDraw, Image # ‡∏û‡∏£‡∏∞‡πÄ‡∏≠‡∏Å‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢

# ==========================================
# ‚öôÔ∏è ‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ (CONFIG)
# ==========================================
DATABASE_PATH = 'database/faces_data.pkl'
MODEL_NAME = 'buffalo_l' 
SIMILARITY_THRESHOLD = 0.40
SHOW_RESULT_TIME = 3 
FONT_PATH = "c:\\WINDOWS\\Fonts\\UPCJB.TTF" 

# ‡∏™‡∏°‡∏∏‡∏î‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏±‡∏Å‡∏®‡∏∂‡∏Å‡∏©‡∏≤ (‡∏£‡∏´‡∏±‡∏™ -> ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ó‡∏¢)
STUDENT_DB = {
    "61": "‡∏ô‡∏≤‡∏¢‡∏û‡∏á‡∏®‡∏ò‡∏£ ‡∏ä‡∏≤‡∏•‡∏µ‡πÇ‡∏™‡∏°",
    "66010002": "‡∏ô.‡∏™.‡∏™‡∏°‡∏®‡∏£‡∏µ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÄ‡∏Å‡πà‡∏á",
    "66010003": "‡∏ä‡∏¥‡∏≠‡∏¥‡πÄ‡∏ô‡∏∞ ‡∏°‡∏≤‡∏Æ‡∏¥‡∏£‡∏∏",
    "12345": "‡πÅ‡∏≠‡∏î‡∏°‡∏¥‡∏ô ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö"
}

is_scan_triggered = False

def on_touch(event, x, y, flags, param):
    global is_scan_triggered
    if event == cv2.EVENT_LBUTTONDOWN: 
        is_scan_triggered = True

def put_thai_text(img, text, position, color, font_size):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ß‡∏≤‡∏î‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏•‡∏á‡∏ö‡∏ô‡∏†‡∏≤‡∏û OpenCV"""
    # 1. ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å OpenCV (BGR) ‡πÄ‡∏õ‡πá‡∏ô PIL (RGB)
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    
    # 2. ‡πÇ‡∏´‡∏•‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå (‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ü‡∏≠‡∏ô‡∏ï‡πå default)
    try:
        font = ImageFont.truetype(FONT_PATH, font_size)
    except IOError:
        # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ default (‡πÅ‡∏ï‡πà‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÇ‡∏ä‡∏ß‡πå‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ô‡∏∞)
        font = ImageFont.load_default()
        print(f"‚ö†Ô∏è ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ü‡∏≠‡∏ô‡∏ï‡πå {FONT_PATH} ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠! ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏ô‡∏∞")

    # 3. ‡∏ß‡∏≤‡∏î‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠
    draw.text(position, text, font=font, fill=color)
    
    # 4. ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô OpenCV (BGR)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

# ==========================================
# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏£‡∏∞‡∏ö‡∏ö (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°)
# ==========================================
print("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î Database...")
try:
    with open(DATABASE_PATH, 'rb') as f:
        data = pickle.load(f)
        known_embeds = np.array(data['embeddings'])
        known_names = data['names']
    print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢: {len(known_names)} ‡∏Ñ‡∏ô")
except Exception as e:
    print(f"‚ùå Error: {e}")
    exit()

print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏°‡πÄ‡∏î‡∏• {MODEL_NAME}...")
app = FaceAnalysis(name=MODEL_NAME, providers=['CPUExecutionProvider'])
app.prepare(ctx_id=0, det_size=(640, 640))

cap = cv2.VideoCapture(1) # ‡∏´‡∏£‡∏∑‡∏≠ 0 ‡∏ï‡∏≤‡∏°‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÄ‡∏ò‡∏≠
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

window_name = 'Touch to Check-In (Thai Supported)'
cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
cv2.setMouseCallback(window_name, on_touch)

print("üöÄ ‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°! (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢)")

while True:
    ret, frame = cap.read()
    if not ret: break

    # --- ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏õ‡∏Å‡∏ï‡∏¥ ---
    if not is_scan_triggered:
        h, w = frame.shape[:2]
        cv2.ellipse(frame, (w // 2, h // 2), (120, 160), 0, 0, 360, (255, 255, 255), 2)
        
        if int(time.time() * 2) % 2 == 0: 
            # ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ cv2.putText ‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ (‡∏°‡∏±‡∏ô‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢)
            cv2.putText(frame, "TAP SCREEN TO SCAN", (w//2 - 140, h - 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        
        cv2.imshow(window_name, frame)

    # --- ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (Scan) ---
    else:
        # Feedback (‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©)
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame) 
        cv2.putText(frame, "Processing...", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)
        cv2.imshow(window_name, frame)
        cv2.waitKey(1) 

        faces = app.get(frame)
        
        for face in faces:
            current_emb = face.embedding
            current_emb = current_emb / np.linalg.norm(current_emb)
            scores = np.dot(known_embeds, current_emb)
            best_idx = np.argmax(scores)
            best_score = scores[best_idx]
            box = face.bbox.astype(int)
            
            if best_score > SIMILARITY_THRESHOLD:
                student_id = known_names[best_idx]
                
                # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ó‡∏¢‡∏à‡∏≤‡∏Å Dict
                real_name = STUDENT_DB.get(student_id, student_id) 
                
                # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß (RGB ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PIL ‡∏Ñ‡∏∑‡∏≠ (0, 255, 0) ‡πÅ‡∏ï‡πà BGR ‡∏Ñ‡∏∑‡∏≠ (0, 255, 0) ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏•‡πâ‡∏ß‡∏ô)
                # ‡πÅ‡∏ï‡πà PIL ‡∏£‡∏±‡∏ö‡∏™‡∏µ‡πÄ‡∏õ‡πá‡∏ô (R, G, B) ‡∏ô‡∏∞
                text_color = (0, 255, 0) 
                display_text = f"{real_name}"
                print(f"‚úÖ ‡πÄ‡∏à‡∏≠‡∏ï‡∏±‡∏ß: {real_name}")
                
            else:
                real_name = "‡πÑ‡∏°‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å"
                text_color = (255, 0, 0) # ‡πÅ‡∏î‡∏á
                display_text = "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

            # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏° (‡πÉ‡∏ä‡πâ OpenCV ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤)
            cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), text_color[::-1], 3) # ‡∏Å‡∏•‡∏±‡∏ö‡∏™‡∏µ‡πÄ‡∏õ‡πá‡∏ô BGR
            
            # ‡∏ß‡∏≤‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏õ‡πâ‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠
            cv2.rectangle(frame, (box[0], box[1]-50), (box[0]+300, box[1]), text_color[::-1], -1)
            
            # üî• ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤!
            # ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡∏™‡πà‡∏á frame ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏±‡∏ö frame ‡πÉ‡∏´‡∏°‡πà‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤
            frame = put_thai_text(frame, display_text, (box[0]+10, box[1]-45), (255, 255, 255), 30)

        if not faces:
             frame = put_thai_text(frame, "‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤", (50, 100), (255, 0, 0), 40)

        cv2.imshow(window_name, frame)
        cv2.waitKey(SHOW_RESULT_TIME * 1000) 

        is_scan_triggered = False
        while cv2.waitKey(1) != -1: pass

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()